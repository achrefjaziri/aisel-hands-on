{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Module 1: Calibration of CCD Imaging Process\n",
    "\n",
    "We implement the algorithm described in \"Statistical Calibration of CCD Imaging Process\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# for the later heavy-duty calculations, we use several CPU cores\n",
    "# during debugging, this could be set to 1\n",
    "num_cores = multiprocessing.cpu_count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "First we need some helper functions to load a series of images from either a folder or a video file.\n",
    "These are the values _I_ in the original paper."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_images_from_folder(pattern, subsampling=32):\n",
    "    # use the provided file name pattern to get all image files\n",
    "    files = glob.glob(pattern)\n",
    "    num_files = len(files)\n",
    "\n",
    "    # read first file to get image dimensions\n",
    "    img = cv2.imread(files[0])\n",
    "    NUM_PIXELS = (img.shape[0] // subsampling) * (img.shape[1] // subsampling)\n",
    "    data = np.ndarray((num_files, NUM_PIXELS, 3))\n",
    "    for i, f in enumerate(files):\n",
    "        img = cv2.imread(f)\n",
    "        data[i, :, :] = img[::subsampling, ::subsampling, :].reshape((NUM_PIXELS, 3))\n",
    "    return data\n",
    "\n",
    "def get_images_from_video(filename, subsampling=32):\n",
    "    video = cv2.VideoCapture(filename)\n",
    "\n",
    "    num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    vidcap = cv2.VideoCapture(filename)\n",
    "    success, img = vidcap.read()\n",
    "\n",
    "    NUM_PIXELS = math.ceil(img.shape[0] / subsampling) * math.ceil(img.shape[1] / subsampling)\n",
    "    data = np.ndarray((num_frames, NUM_PIXELS, 3))\n",
    "\n",
    "    i = 0\n",
    "    while success:\n",
    "        data[i, :, :] = img[::subsampling, ::subsampling, :].reshape((NUM_PIXELS, 3))\n",
    "        success, img = vidcap.read()\n",
    "        i += 1\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this example we use an video file with pedestrians walking across an empty place."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!wget https://github.com/ccc-frankfurt/aisel-hands-on/blob/main/data/epflpedestshort.avi?raw=true"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the pixel data for all\n",
    "data = get_images_from_video(\"./epflpedestshort.avi\")\n",
    "num_files = data.shape[0]\n",
    "num_pixels = data.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we initialize all arrays we will later on use with the correct dimensions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = [1 for i in range(num_files)]\n",
    "b = [0 for i in range(num_files)]\n",
    "g = [i for i in range(256)]\n",
    "E = np.zeros(num_pixels)\n",
    "w = np.ones(num_files) / num_files\n",
    "sigma = np.ones(num_files)\n",
    "F = np.zeros(num_files)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 1: Predict irradiance for each pixel\n",
    "\n",
    "First step in each loop will be the calculation of the predicted irradiance _E_ (formula 9 in the paper):\n",
    "\n",
    "$E = \\sum_i w_i \\frac{g(I_i) - b_i}{a_i}$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# we use a function instead of a array index so we can np.vectorize it\n",
    "def g_func(x):\n",
    "    return g[int(x)]\n",
    "g_func = np.vectorize(g_func)\n",
    "\n",
    "def calc_E(w, data, b, a):\n",
    "    def calc_E_single(w, data, b, a, i):\n",
    "        # using numpy array broadcast the irradiance is calculated without looping over each pixel\n",
    "        return w[i] * (g_func(data[i, :]) - b[i]) / a[i]\n",
    "\n",
    "    # calculate the irradiance for each file seperately and sum the results\n",
    "    results = Parallel(n_jobs=num_cores, mmap_mode=None)(\n",
    "        delayed(calc_E_single)(w, data, b, a, i) for i in range(num_files))\n",
    "    return sum(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 2: calculated residual error for each pixel\n",
    "\n",
    "Next we calculate the residual errors _e_ and the median errors across each pool of pixels (formulas 11 and 12)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def pool(data, k, z, eps=1):\n",
    "    # find each pool of pixels around z with a maximum difference of epsilon=1\n",
    "    image = data[k, :]\n",
    "    mask = np.abs(image - z) < eps\n",
    "    return mask.nonzero()\n",
    "\n",
    "\n",
    "def calc_e(data, E, a, b):\n",
    "    # we use the median instead of the 66-percentage median due to numpy not having a vectorized version of the latter\n",
    "    pool_errors = np.ndarray((num_pixels, num_files))\n",
    "    median_errors = np.ndarray((num_files,))\n",
    "    for k in range(num_files):\n",
    "        errors_per_pixel = a[k] * E + b[k] - g_func(data[k, :])\n",
    "        for i, z in enumerate(data[k, :]):\n",
    "            pool_z = pool(data, k, z)\n",
    "            pool_errors[i, k] = np.mean([errors_per_pixel[y] for y in pool_z])\n",
    "\n",
    "        # the value c=1.265 is due to us correcting the green bands only (paragraph 3.1)\n",
    "        # if we want to correct other colors, use c = 1.333\n",
    "        median_errors[k] = 1.265 * np.median(errors_per_pixel - pool_errors[:, k])\n",
    "    return pool_errors, median_errors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 3: Optimize the parameters\n",
    "\n",
    "After we have calculated the mean errors we optimize the formula 15 with regards to our vectors  _g , a and b_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calc_gradients():\n",
    "    #since our optimzing library only supports one vector argument, pack delta_a, delta_b and delta_g into one vector\n",
    "    args = np.zeros((2 * num_files + 256,))\n",
    "    args[0:num_files] = 1\n",
    "\n",
    "    res = minimize(calc_total_F_error, args, options={\"maxiter\": 10})\n",
    "\n",
    "    # unpack the optimized values\n",
    "    da = res.x[0: num_files]\n",
    "    db = res.x[num_files:2 * num_files]\n",
    "    dg = res.x[2 * num_files:]\n",
    "    return da, db, dg\n",
    "\n",
    "\n",
    "def calc_total_F_error(args):\n",
    "    #caluclates formula 15, the variance-weighted difference between our measured residuals and the theoretical error\n",
    "    def calc_total_F_error_single(E, da, db, dg, w, data, k):\n",
    "        F = calc_F(E, da, db, dg, w, data, k)\n",
    "        return (e[:, k] - F) ** 2 / sigma[k]\n",
    "\n",
    "    #unpack the arguments\n",
    "    da = args[0:num_files]\n",
    "    db = args[num_files:2 * num_files]\n",
    "    dg = args[2 * num_files:]\n",
    "\n",
    "    results = [calc_total_F_error_single(E, da, db, dg, w, green_channel, i) for i in range(num_files)]\n",
    "    results = sum(results).sum()\n",
    "    return results\n",
    "\n",
    "\n",
    "def calc_F(E, da, db, dg, w, data, k):\n",
    "    #calucate formula 13, the theoretical error at each iteration\n",
    "    def calc_F_single(E, da, db, dg, w, data, k, i):\n",
    "        if i == k:\n",
    "            return 0\n",
    "        dg_of_data = np.ndarray((num_pixels,))\n",
    "        dg_of_data[:] = [dg[int(x)] for x in data[i, :]]\n",
    "        return w[i] * a[k] / da[i] * (dg_of_data - db[i] - E[:] * da[i])\n",
    "\n",
    "    results = Parallel(n_jobs=num_cores, mmap_mode=None)(\n",
    "        delayed(calc_F_single)(E, da, db, dg, w, data, k, i) for i in range(num_files))\n",
    "    total = sum(results)\n",
    "    total += (w[k] - 1) * (g_func(data[k, :]) - b[k] - E[:] * a[k])\n",
    "    return total"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Step 4: Iterating the previous steps\n",
    "\n",
    "Last step is putting it all together, and running several iterations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LEARN_RATE = 0.1\n",
    "NUM_LEARNING_ITERATIONS = 10\n",
    "\n",
    "for j in range(NUM_LEARNING_ITERATIONS):\n",
    "    # we are interested in green only\n",
    "    green_channel = data[:, :, 1]\n",
    "\n",
    "    # see step 1\n",
    "    E = calc_E(w, green_channel, b, a)\n",
    "\n",
    "    # see step 2\n",
    "    e, median_errors = calc_e(green_channel, E, a, b)\n",
    "    w = 1 / median_errors\n",
    "    sigma = median_errors\n",
    "\n",
    "    # see step 3\n",
    "    da, db, dg = calc_gradients()\n",
    "\n",
    "    #update the process parameters (formula 16)\n",
    "    a = a - LEARN_RATE * da\n",
    "    b = b - LEARN_RATE * db\n",
    "    g = g - LEARN_RATE * dg\n",
    "\n",
    "    #plot img over time\n",
    "    example_img = data[0]\n",
    "    plt.imshow(calibrate(example_img))\n",
    "    plt.canvas.draw()\n",
    "\n",
    "\n",
    "# lastly, save our calibration parameters in the file system so it can later be used\n",
    "pickle.dump(a, open(\"a.param\", \"wb\"))\n",
    "pickle.dump(b, open(\"b.param\", \"wb\"))\n",
    "pickle.dump(g, open(\"g.param\", \"wb\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To calibrate using the estimated parameters is a simple function:\n",
    "$\\frac{g(I) - b}{a}$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calibrate(img, a, b, g):\n",
    "    def apply_g(x):\n",
    "        return g[int(x)]\n",
    "    apply_g = np.vectorize(apply_g)\n",
    "\n",
    "    return (apply_g(img) - b) / a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}